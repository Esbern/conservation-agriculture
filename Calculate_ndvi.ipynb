{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esbern/conservation-agriculture/blob/main/Calculate_ndvi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "450f0b98-6b14-4d35-80db-33df8f18b71c",
      "metadata": {
        "id": "450f0b98-6b14-4d35-80db-33df8f18b71c"
      },
      "source": [
        "# Comparing NDVI for Conservation and non conservation agricultur"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6074d9-6bd6-46c9-85a7-df8d9c114ac6",
      "metadata": {
        "id": "1d6074d9-6bd6-46c9-85a7-df8d9c114ac6"
      },
      "source": [
        "## Defining the Problem\n",
        "We have 8 fields comparison plots with a Conversational and a non conversational agricultural field neighbouring each other. Of these 1 is a  pilot (nr 7) which consists of small subplots with in a larger field is excludes from the NDVI calculation since the subplots are too small to isolate on the landsat image. For"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ca57bd-e7a3-4cfd-9dea-f88f93cf78c2",
      "metadata": {
        "id": "57ca57bd-e7a3-4cfd-9dea-f88f93cf78c2"
      },
      "source": [
        "## Overall workflow\n",
        "1. Setup the GEE work environment\n",
        "2. Load the fields from Github\n",
        "3. Extract the Landsat data for the given areas and period\n",
        "4. Identify which pixels are within which fields/treatments (Intersect)\n",
        "5. Process the pixels (Decode quality byte, convert the time stamp to Year, Month Day)\n",
        "6. Join filed/treatment data to the pixels\n",
        "7. Filter pixels for clouds\n",
        "8. Calculate the average NDVI for each Year, Month for each field/treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb5541fe-258f-424c-b5b3-d00acac26e6c",
      "metadata": {
        "id": "fb5541fe-258f-424c-b5b3-d00acac26e6c"
      },
      "source": [
        "## Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c9ce10-807a-4baa-b7de-b201bb42a1a6",
      "metadata": {
        "id": "e5c9ce10-807a-4baa-b7de-b201bb42a1a6"
      },
      "source": [
        "### Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e03b31c-5aa4-41b5-a709-892664eb5070",
      "metadata": {
        "id": "4e03b31c-5aa4-41b5-a709-892664eb5070"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import numpy as np\n",
        "import geemap\n",
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate()"
      ],
      "metadata": {
        "id": "xRh76IqbQsnu"
      },
      "id": "xRh76IqbQsnu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Initialize(project=\"ee-holmes-e23\")"
      ],
      "metadata": {
        "id": "v5-4MZEDQlb2"
      },
      "id": "v5-4MZEDQlb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8b721e9-a098-4c9c-b210-9befe55fa02c",
      "metadata": {
        "id": "d8b721e9-a098-4c9c-b210-9befe55fa02c"
      },
      "source": [
        "If the machine is a new one copy the gee credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244e45ad-14bb-4ce8-80a7-e6292ef77439",
      "metadata": {
        "id": "244e45ad-14bb-4ce8-80a7-e6292ef77439"
      },
      "outputs": [],
      "source": [
        "geemap.ee_initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16c1ae99-5bc5-4cc0-8799-eb85b77c59a2",
      "metadata": {
        "id": "16c1ae99-5bc5-4cc0-8799-eb85b77c59a2"
      },
      "source": [
        "### Load Data\n",
        "Load a geojson document that defines the field and treatment type for each pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4997637-d695-49ea-b506-1e94b53c25cf",
      "metadata": {
        "id": "b4997637-d695-49ea-b506-1e94b53c25cf"
      },
      "outputs": [],
      "source": [
        "fields = gpd.read_file(\"https://raw.githubusercontent.com/Esbern/conservation-agriculture/main/sampel_fields.geojson\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf80de9d-64ac-45a0-8fc0-e63f5121fead",
      "metadata": {
        "id": "cf80de9d-64ac-45a0-8fc0-e63f5121fead"
      },
      "outputs": [],
      "source": [
        "attribute_to_color = {\n",
        "    'CT': '#FF0000',  # Red\n",
        "    'MT': '#00FF00',  # Green\n",
        "}\n",
        "fields['color'] = fields['tillage'].map(attribute_to_color)\n",
        "Map = geemap.Map(center=(55, 13), zoom=4)\n",
        "Map.add_gdf(fields, layer_name=\"Fields\",\n",
        "            style_callback=lambda x: {'fillColor': x['properties']['color']})\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5120bda-98fd-4e21-a28e-81335a68e1ea",
      "metadata": {
        "id": "f5120bda-98fd-4e21-a28e-81335a68e1ea"
      },
      "source": [
        "### Extract the Landsat data for the given areas and period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987f35c8-e8b7-4a18-9fae-7af2ba8eefc4",
      "metadata": {
        "id": "987f35c8-e8b7-4a18-9fae-7af2ba8eefc4"
      },
      "outputs": [],
      "source": [
        "# Convert Dataframe to ee object\n",
        "fields_ee = geemap.geopandas_to_ee(fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44a2a66-1b80-4706-9b3a-96464c9aff82",
      "metadata": {
        "id": "f44a2a66-1b80-4706-9b3a-96464c9aff82"
      },
      "outputs": [],
      "source": [
        "# Identify Landsat images covering the fields for the given priod\n",
        "L7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\")\n",
        "col = L7 \\\n",
        "  .filterBounds(fields_ee) \\\n",
        "  .filterDate('2010-01-01', '2016-01-01') \\\n",
        "  .select('B3','B4','QA_PIXEL')\n",
        "count = col.size()\n",
        "count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50e284e3-4172-4101-a471-c09ecf2bac62",
      "metadata": {
        "id": "50e284e3-4172-4101-a471-c09ecf2bac62"
      },
      "outputs": [],
      "source": [
        "# Collect the pixel values and convert them to a local dataframe\n",
        "\n",
        "pixelInfoBbox= col.getRegion(geometry=fields_ee,scale=30)\n",
        "pixelList = pixelInfoBbox.getInfo()\n",
        "all_pixels_df = pd.DataFrame(pixelList[1:], columns=pixelList[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c72cfff-6fbd-4d91-a50e-4561d0e37bb1",
      "metadata": {
        "id": "6c72cfff-6fbd-4d91-a50e-4561d0e37bb1"
      },
      "source": [
        "### Identify which pixels are within which fields/treatments (Intersect)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f833b5-d466-449a-bddc-6088f6a12848",
      "metadata": {
        "id": "c5f833b5-d466-449a-bddc-6088f6a12848"
      },
      "outputs": [],
      "source": [
        "#Extract all unique pixel coordinates and convert them to a GeoPandas dataframe\n",
        "pixel_df = all_pixels_df.groupby(['longitude', 'latitude']).size().reset_index(name='counts')\n",
        "pixels_gdf = gpd.GeoDataFrame(\n",
        "    pixel_df, geometry=gpd.points_from_xy(pixel_df.longitude, pixel_df.latitude), crs=\"EPSG:4326\"\n",
        ")\n",
        "pixel_fields_gdf = gpd.overlay( pixels_gdf,fields, how='intersection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31a8379-c80f-44c3-9638-01f78b0310c2",
      "metadata": {
        "id": "b31a8379-c80f-44c3-9638-01f78b0310c2"
      },
      "outputs": [],
      "source": [
        "def style_function(feature):\n",
        "    return {\n",
        "        'color': feature['properties']['color'],  # This sets the border color\n",
        "        'fillColor': feature['properties']['color'],  # This sets the fill color\n",
        "        'fillOpacity': 0.5,\n",
        "        'weight': 1,\n",
        "    }\n",
        "\n",
        "Map = geemap.Map(center=(55, 13), zoom=4)\n",
        "Map.add_gdf(fields, layer_name=\"Fields\",\n",
        "            style_callback=lambda x: {'fillColor': x['properties']['color']})\n",
        "Map.add_gdf(pixel_fields_gdf, layer_name=\"pixels\")\n",
        "\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22601a81-2db8-44f1-8828-233fbb81a63f",
      "metadata": {
        "id": "22601a81-2db8-44f1-8828-233fbb81a63f"
      },
      "source": [
        "### Process the pixels (Caclulate NDVIFilter pixels for clouds and convert the time stamp to Year, Month Day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06fdc2e-759d-4cc7-b641-5178ade1c45f",
      "metadata": {
        "id": "f06fdc2e-759d-4cc7-b641-5178ade1c45f"
      },
      "outputs": [],
      "source": [
        "#Process Time and NDVI\n",
        "all_pixels_df['time'] = pd.to_datetime(all_pixels_df['time'], unit='ms')\n",
        "\n",
        "# Extract year, month, and day to separate columns\n",
        "all_pixels_df['year'] = all_pixels_df['time'].dt.year\n",
        "all_pixels_df['month'] = all_pixels_df['time'].dt.month\n",
        "all_pixels_df['day'] = all_pixels_df['time'].dt.day\n",
        "\n",
        "# Calculate NDVI and add it as a new column\n",
        "all_pixels_df['NDVI'] = (all_pixels_df['B4'] - all_pixels_df['B3']) / (all_pixels_df['B4'] + all_pixels_df['B3'])\n",
        "\n",
        "# Handle potential division by zero or NaN values\n",
        "all_pixels_df['NDVI'] = all_pixels_df['NDVI'].replace([np.inf, -np.inf], np.nan)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3e3fa5-9830-4ca3-9d5c-57ddf46fa151",
      "metadata": {
        "id": "9d3e3fa5-9830-4ca3-9d5c-57ddf46fa151"
      },
      "outputs": [],
      "source": [
        "# Function to decode the QA_PIXEL column, modified to handle NaN values\n",
        "def decode_qa_pixel(value):\n",
        "    # Check if the value is NaN and return NaN for all attributes if true\n",
        "    if pd.isna(value):\n",
        "        return pd.Series([np.nan] * 11, index=[\n",
        "            'Fill', 'Dilated Cloud', 'Cloud', 'Cloud Shadow', 'Snow',\n",
        "            'Clear', 'Water', 'Cloud Confidence', 'Cloud Shadow Confidence',\n",
        "            'Snow/Ice Confidence', 'Cirrus Confidence'])\n",
        "\n",
        "    # Convert float to int and then to binary string, stripping the '0b' prefix\n",
        "    binary_str = format(int(value), '016b')\n",
        "\n",
        "    # Decode each bit based on the descriptions provided\n",
        "    attributes = {\n",
        "        'Fill': 'Fill data' if binary_str[-1] == '1' else 'Image data',\n",
        "        'Dilated Cloud': 'Cloud dilation' if binary_str[-2] == '1' else 'Cloud is not dilated or no cloud',\n",
        "        'Cloud': 'High confidence cloud' if binary_str[-4] == '1' else 'Cloud confidence is not high',\n",
        "        'Cloud Shadow': 'High confidence cloud shadow' if binary_str[-5] == '1' else ' Cloud Shadow Confidence is not high',\n",
        "        'Snow': 'High confidence snow cover' if binary_str[-6] == '1' else 'Snow/Ice Confidence is not high',\n",
        "        'Clear': 'Cloud and Dilated Cloud bits not set' if binary_str[-7] == '1' else 'Cloud or Dilated Cloud bits set',\n",
        "        'Water': 'Water' if binary_str[-8] == '1' else 'Land or cloud',\n",
        "        'Cloud Confidence': {\n",
        "            '00': 'No cloud confidence level set',\n",
        "            '01': 'Low cloud confidence',\n",
        "            '10': 'Medium cloud confidence',\n",
        "            '11': 'High cloud confidence',\n",
        "        }[binary_str[-10:-8]],\n",
        "        'Cloud Shadow Confidence': {\n",
        "            '00': 'No cloud shadow confidence level set',\n",
        "            '01': 'Low cloud shadow confidence',\n",
        "            '10': 'Reserved',\n",
        "            '11': 'High cloud shadow confidence',\n",
        "        }[binary_str[-12:-10]],\n",
        "        'Snow/Ice Confidence': {\n",
        "            '00': 'No snow/ice confidence level set',\n",
        "            '01': 'Low snow/ice confidence',\n",
        "            '10': 'Reserved',\n",
        "            '11': 'High snow/ice confidence',\n",
        "        }[binary_str[-14:-12]],\n",
        "        'Cirrus Confidence': {\n",
        "            '00': 'No cirrus confidence level set',\n",
        "            '01': 'Low cirrus confidence',\n",
        "            '10': 'Reserved',\n",
        "            '11': 'High cirrus confidence',\n",
        "        }[binary_str[-16:-14]],\n",
        "    }\n",
        "\n",
        "    return pd.Series(attributes)\n",
        "\n",
        "# Apply the decode function to the QA_PIXEL column and assign the result to new columns\n",
        "new_columns = all_pixels_df['QA_PIXEL'].apply(decode_qa_pixel)\n",
        "all_pixels_df = pd.concat([all_pixels_df, new_columns], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122d5662-b718-4182-af01-440c6d542076",
      "metadata": {
        "id": "122d5662-b718-4182-af01-440c6d542076"
      },
      "source": [
        "### Join filed/treatment data to the pixels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6b4118-8e6c-4088-be4d-069d720a9dd7",
      "metadata": {
        "id": "0d6b4118-8e6c-4088-be4d-069d720a9dd7"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(all_pixels_df, pixel_fields_gdf[['longitude', 'latitude', 'pair', 'tillage']], on=['longitude', 'latitude'], how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6d256b-f349-4ef1-b2c7-0040f6d70f49",
      "metadata": {
        "id": "9b6d256b-f349-4ef1-b2c7-0040f6d70f49"
      },
      "source": [
        "### Filter pixels for clouds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f04406f8-48e3-491a-82d9-da095cf82103",
      "metadata": {
        "id": "f04406f8-48e3-491a-82d9-da095cf82103"
      },
      "outputs": [],
      "source": [
        "filtered_df = merged_df[merged_df['Clear'] == \"Cloud and Dilated Cloud bits not set\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv(\"/content/drive/MyDrive/Conservation_agri/pixl_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "MrC9yWW9J4_c"
      },
      "id": "MrC9yWW9J4_c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ROD3OsM-47lX"
      },
      "id": "ROD3OsM-47lX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9903ba-3761-43b9-b1a9-eed6b1a2ac13",
      "metadata": {
        "id": "ff9903ba-3761-43b9-b1a9-eed6b1a2ac13"
      },
      "outputs": [],
      "source": [
        "filtered_df.to_excel(\"/content/drive/MyDrive/Conservation_agri/pixler.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you just need the plots"
      ],
      "metadata": {
        "id": "LduusyamZl6a"
      },
      "id": "LduusyamZl6a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7c0805"
      },
      "source": [
        "filtered_df = pd.read_excel(\"/content/drive/MyDrive/Conservation_agri/pixler.xlsx\")"
      ],
      "id": "7a7c0805",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start plotting"
      ],
      "metadata": {
        "id": "6leYyOgtJDta"
      },
      "id": "6leYyOgtJDta"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add climat referance value"
      ],
      "metadata": {
        "id": "BiwgNgBaEpLo"
      },
      "id": "BiwgNgBaEpLo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "climat_data = {\n",
        "    \"Month\": [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"],\n",
        "    \"Average of Maximum Temperature\": [3.8, 4, 6.9, 11.6, 16.1, 19.1, 21.1, 21.2, 17.5, 12.8, 8.3, 6],\n",
        "    \"Average Temperature\": [1.9, 1.8, 3.7, 7.4, 11.7, 14.9, 16.7, 16.8, 13.9, 10.1, 6.3, 4.2],\n",
        "    \"Average of Minimum Temperature\": [-0.3, -0.6, 0.8, 3.4, 7.3, 10.6, 12.3, 12.7, 10.4, 7.4, 3.9, 2],\n",
        "    \"Total Precipitation\": [66, 49.3, 43.1, 37.7, 47.4, 66.9, 69.5, 86.1, 82.6, 84.5, 67.4, 81.2]\n",
        "}"
      ],
      "metadata": {
        "id": "9joDmPMCEoeT"
      },
      "id": "9joDmPMCEoeT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- ANOVA to test differences between groups (This part remains the same) ---\n",
        "anova_series = filtered_df.groupby(['month']).apply(\n",
        "    lambda x: stats.f_oneway(x[x['tillage'] == 'MT']['NDVI'], x[x['tillage'] == 'CT']['NDVI'])\n",
        ")\n",
        "anova_results = pd.DataFrame(anova_series.tolist(), index=anova_series.index, columns=['F-Statistic', 'p-Value'])\n",
        "anova_results['Significant'] = anova_results['p-Value'] < 0.05\n",
        "\n",
        "print(\"ANOVA Results:\")\n",
        "print(anova_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1. Use .agg() to get the mean, count (n), and standard deviation for each group.\n",
        "summary_stats = filtered_df.groupby(['month', 'tillage'])['NDVI'].agg(\n",
        "    Mean='mean',\n",
        "    Count='count',  # 'count' provides the number of observations (n)\n",
        "    Std_Dev='std'\n",
        ").reset_index()\n",
        "\n",
        "# 2. Calculate the Standard Error of the Mean (SEM).\n",
        "# SEM = Standard Deviation / sqrt(Number of Observations)\n",
        "summary_stats['Std_Error'] = summary_stats['Std_Dev'] / np.sqrt(summary_stats['Count'])\n",
        "\n",
        "# 3. Calculate the 95% confidence interval bounds.\n",
        "# The z-score for 95% confidence is ~1.96. stats.norm.ppf(0.975) gives the precise value.\n",
        "z_score = stats.norm.ppf(0.975)\n",
        "summary_stats['CI_Lower'] = summary_stats['Mean'] - z_score * summary_stats['Std_Error']\n",
        "summary_stats['CI_Upper'] = summary_stats['Mean'] + z_score * summary_stats['Std_Error']\n",
        "\n",
        "\n",
        "# 4. Display the final, comprehensive table.\n",
        "print(\"\\nSummary Statistics and Confidence Intervals:\")\n",
        "# We select the columns we care most about for the final printout.\n",
        "print(summary_stats[['month', 'tillage', 'Mean', 'Count', 'CI_Lower', 'CI_Upper']])"
      ],
      "metadata": {
        "id": "ULmnK_2bYi9X"
      },
      "id": "ULmnK_2bYi9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "box_plot = sns.boxplot(x='month', y='NDVI', hue='tillage', data=filtered_df, palette=['white', 'white'])\n",
        "plt.title('NDVI by Month and Tillage Regime')\n",
        "hue_order = box_plot.get_legend_handles_labels()[1]\n",
        "num_months = len(filtered_df['month'].unique())\n",
        "month_names = {2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
        "               7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\"}\n",
        "box_plot.set_xticklabels([month_names[int(tick.get_text())] for tick in box_plot.get_xticklabels()])\n",
        "\n",
        "for i, patch in enumerate(box_plot.patches):\n",
        "    hue_index = (i // num_months) % len(hue_order)\n",
        "    tillage_type = hue_order[hue_index]\n",
        "    if tillage_type == 'MT':\n",
        "        patch.set_hatch('///')\n",
        "        patch.set_edgecolor('black')\n",
        "    else:\n",
        "        patch.set_edgecolor('black')\n",
        "box_plot.legend_.remove()\n",
        "\n",
        "\n",
        "# 1. Prepare the data for all three table rows\n",
        "p_values = ['{:.2e}'.format(p) for p in anova_results['p-Value']]\n",
        "\n",
        "# Create the NEW row for Mean values, formatted to 3 decimal places\n",
        "mean_values = []\n",
        "sorted_months = sorted(filtered_df['month'].unique())\n",
        "for month in sorted_months:\n",
        "    ct_mean = summary_stats.loc[(summary_stats['month'] == month) & (summary_stats['tillage'] == 'CT'), 'Mean'].iloc[0]\n",
        "    mt_mean = summary_stats.loc[(summary_stats['month'] == month) & (summary_stats['tillage'] == 'MT'), 'Mean'].iloc[0]\n",
        "    mean_values.append(f\"CT: {ct_mean:.3f}\\nMT: {mt_mean:.3f}\")\n",
        "\n",
        "# Create the row for the number of observations (N)\n",
        "n_counts = []\n",
        "for month in sorted_months:\n",
        "    ct_count = summary_stats.loc[(summary_stats['month'] == month) & (summary_stats['tillage'] == 'CT'), 'Count'].iloc[0]\n",
        "    mt_count = summary_stats.loc[(summary_stats['month'] == month) & (summary_stats['tillage'] == 'MT'), 'Count'].iloc[0]\n",
        "    n_counts.append(f\"CT: {ct_count}\\nMT: {mt_count}\")\n",
        "\n",
        "# 2. Update the cellText and rowLabels to use the new Mean row\n",
        "table_data = [mean_values, p_values, n_counts]\n",
        "row_labels = ['Mean (CT/MT)', 'p-Value', 'N (CT/MT)']\n",
        "\n",
        "# 3. Add the table with the updated rows\n",
        "the_table = ax.table(cellText=table_data,\n",
        "                     rowLabels=row_labels,\n",
        "                     loc='bottom',\n",
        "                     bbox=[0.0, -0.45, 1.0, 0.3])\n",
        "\n",
        "# 4. Adjust font size and row height\n",
        "the_table.auto_set_font_size(False)\n",
        "the_table.set_fontsize(9)\n",
        "the_table.scale(1, 1.0)\n",
        "\n",
        "# 5. Adjust overall plot layout to make space for the table\n",
        "plt.subplots_adjust(bottom=0.3)\n",
        "\n",
        "# Show and save the plot\n",
        "plt.show()\n",
        "fig.savefig('till_NDVI.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "g_naHfna6sGB"
      },
      "id": "g_naHfna6sGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(climat_data)\n",
        "\n",
        "# Plotting\n",
        "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "# Temperature plot (line)\n",
        "ax1.set_xlabel('Month')\n",
        "ax1.set_ylabel('Temperature (Â°C)')\n",
        "ax1.plot(df['Month'], df['Average of Maximum Temperature'], linestyle='--', linewidth=2, label='Avg of Max Temp', marker='o')\n",
        "ax1.plot(df['Month'], df['Average Temperature'], linestyle='-', linewidth=2, label='Avg Temp', marker='v')\n",
        "ax1.plot(df['Month'], df['Average of Minimum Temperature'], color=\"black\", linestyle='-.', linewidth=2, label='Avg of Min Temp', marker='s')\n",
        "ax1.tick_params(axis='y')\n",
        "#ax1.legend(loc='upper left')\n",
        "\n",
        "# Precipitation plot (bar) using twin axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('Total Precipitation (mm)')\n",
        "ax2.bar(df['Month'], df['Total Precipitation'], color='grey', label='Total Precipitation', alpha=0.6)\n",
        "ax2.tick_params(axis='y')\n",
        "#ax2.legend(loc='upper right')\n",
        "\n",
        "# Title\n",
        "plt.title('Monthly Climate Data: Temperature and Precipitation')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save the plot in high resolution\n",
        "fig.savefig('climate_data_plot.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "GethDDJI3Rgf"
      },
      "id": "GethDDJI3Rgf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}